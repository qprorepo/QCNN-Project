{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft2, ifft2\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = cv2.imread(lenna_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if lenna_image is None:\n",
    "    raise ValueError(f\"Error loading Lenna image from path: {lenna_image_path}\")\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Define Quantum Fourier Transform (QFT)\n",
    "def QFT(image):\n",
    "    return fft2(image)\n",
    "\n",
    "# Define inverse Quantum Fourier Transform (iQFT)\n",
    "def iQFT(image):\n",
    "    return ifft2(image)\n",
    "\n",
    "# Define padding operation\n",
    "def pad_to_same_size(image, target_shape):\n",
    "    pad_height = target_shape[0] - image.shape[0]\n",
    "    pad_width = target_shape[1] - image.shape[1]\n",
    "    pad_height_top = pad_height // 2\n",
    "    pad_height_bottom = pad_height - pad_height_top\n",
    "    pad_width_left = pad_width // 2\n",
    "    pad_width_right = pad_width - pad_width_left\n",
    "    return np.pad(image, ((pad_height_top, pad_height_bottom), (pad_width_left, pad_width_right)), mode='constant')\n",
    "\n",
    "# Define convolution in frequency domain\n",
    "def quantum_convolution(image, kernel):\n",
    "    # Pad image and kernel to the same size\n",
    "    target_shape = (image.shape[0] + kernel.shape[0] - 1, image.shape[1] + kernel.shape[1] - 1)\n",
    "    padded_image = pad_to_same_size(image, target_shape)\n",
    "    padded_kernel = pad_to_same_size(kernel, target_shape)\n",
    "    \n",
    "    # Apply QFT\n",
    "    qft_image = QFT(padded_image)\n",
    "    qft_kernel = QFT(padded_kernel)\n",
    "    \n",
    "    # Element-wise multiplication\n",
    "    convolved = qft_image * qft_kernel\n",
    "    \n",
    "    # Apply inverse QFT\n",
    "    result = iQFT(convolved)\n",
    "    \n",
    "    # Crop the result to the original image size\n",
    "    result = np.abs(result)\n",
    "    crop_size = ((target_shape[0] - image.shape[0]) // 2, (target_shape[1] - image.shape[1]) // 2)\n",
    "    result = result[crop_size[0]:crop_size[0] + image.shape[0], crop_size[1]:crop_size[1] + image.shape[1]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define example kernel\n",
    "kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "\n",
    "# Apply quantum convolution on MNIST image\n",
    "mnist_convolved = quantum_convolution(q_mnist_image, kernel)\n",
    "\n",
    "# Apply quantum convolution on Lenna image\n",
    "lenna_convolved = quantum_convolution(q_lenna_image, kernel)\n",
    "\n",
    "# Visualize the results\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# MNIST\n",
    "axs[0, 0].imshow(q_mnist_image, cmap='gray')\n",
    "axs[0, 0].set_title('Original MNIST Image')\n",
    "axs[0, 1].imshow(mnist_convolved, cmap='gray')\n",
    "axs[0, 1].set_title('Convolved MNIST Image')\n",
    "\n",
    "# Lenna\n",
    "axs[1, 0].imshow(q_lenna_image, cmap='gray')\n",
    "axs[1, 0].set_title('Original Lenna Image')\n",
    "axs[1, 1].imshow(lenna_convolved, cmap='gray')\n",
    "axs[1, 1].set_title('Convolved Lenna Image')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5381954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "import cv2\n",
    "\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = cv2.imread(lenna_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if lenna_image is None:\n",
    "    raise ValueError(f\"Error loading Lenna image from path: {lenna_image_path}\")\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "pepper_image_path = 'C:/Users/ACER/Desktop/download.jpg'\n",
    "pepper_image = cv2.imread(pepper_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if pepper_image is None:\n",
    "    raise ValueError(f\"Error loading Pepper image from path: {pepper_image_path}\")\n",
    "pepper_image = cv2.resize(pepper_image, (28, 28))\n",
    "q_pepper_image = pepper_image / 255.0\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the equations as functions\n",
    "def tensor_product(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, 2 * (Q_in + Q_f), 2 * gate_count(Q_in, Q_f)\n",
    "\n",
    "def composition(N, d, K, Q_in, Q_f_smaller):\n",
    "    return N**4 * d**2 * K**2, Q_in + Q_f_smaller, gate_count(Q_in, Q_f_smaller) + gate_additional()\n",
    "\n",
    "def single_kernel_element(N, Q_in):\n",
    "    return N**4, Q_in, limited_gates()\n",
    "\n",
    "def complex_kernel_element(N, Q_in):\n",
    "    return 2 * N**4, Q_in, gate_count_rotations()\n",
    "\n",
    "def multiple_kernels(M, N, d, K, Q_in, Q_f_kernel):\n",
    "    return M * N**6 * d**2 * K**2, N * (Q_in + Q_f_kernel), M * gate_count(Q_in, Q_f_kernel)\n",
    "\n",
    "def stride(N, d, K, S, Q_in, Q_f):\n",
    "    return (N**6 * d**2 * K**2) // S**2, (Q_in + Q_f // S**2), gate_count(Q_in, Q_f // S**2)\n",
    "\n",
    "def pooling(N, Q_in, Q_f):\n",
    "    return N**4, (Q_in + Q_f), gate_pooling()\n",
    "\n",
    "def bn(N, Q_in, Q_f):\n",
    "    return N**4, (Q_in + Q_f), gate_normalization()\n",
    "\n",
    "def weighted_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, 2 * (Q_in + Q_f), gate_controlled_rotations()\n",
    "\n",
    "def grouped_kernels(N, G, d, K, Q_in, Q_f):\n",
    "    return (N // G)**6 * d**2 * K**2, (N // G) * (Q_in + Q_f // G), (N // G) * gate_count(Q_in, Q_f // G)\n",
    "\n",
    "def dilated_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * (K-1)**2, (Q_in + Q_f), gate_count(Q_in, Q_f)\n",
    "\n",
    "def depthwise_separable_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**4 * d + N**2 * d * K**2, (Q_in + d * Q_f), gate_depthwise() + gate_pointwise()\n",
    "\n",
    "def quc_with_pd_circuit(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, increased_qubits_pd(), gate_padding() + gate_count(Q_in, Q_f)\n",
    "\n",
    "def quc_with_pd_using_padded_kernel(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + Q_f), gate_count(Q_in, Q_f)\n",
    "\n",
    "def quc_with_pd_and_pre_padded_image(N, d, K, Q_in, padded_Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + padded_Q_f), gate_count(Q_in, padded_Q_f)\n",
    "\n",
    "def alternative_quc_with_pd_via_fts(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + Q_f), gate_ft() + gate_conv_f()\n",
    "\n",
    "# Placeholder functions for gate counts and other constants\n",
    "def gate_count(Q_in, Q_f): return Q_in * Q_f\n",
    "def gate_additional(): return 10\n",
    "def limited_gates(): return 5\n",
    "def gate_count_rotations(): return 15\n",
    "def gate_pooling(): return 20\n",
    "def gate_normalization(): return 10\n",
    "def gate_controlled_rotations(): return 25\n",
    "def gate_depthwise(): return 8\n",
    "def gate_pointwise(): return 12\n",
    "def increased_qubits_pd(): return 5\n",
    "def gate_padding(): return 7\n",
    "def gate_ft(): return 9\n",
    "def gate_conv_f(): return 11\n",
    "\n",
    "# Plotting the results for a specific set of parameters\n",
    "N = 28\n",
    "d = 1\n",
    "K = 3\n",
    "Q_in = 5\n",
    "Q_f = 4\n",
    "Q_f_smaller = 3\n",
    "Q_f_kernel = 2\n",
    "S = 2\n",
    "M = 1\n",
    "G = 2\n",
    "padded_Q_f = 6\n",
    "\n",
    "techniques = [\n",
    "    (\"Tensor product\", tensor_product(N, d, K, Q_in, Q_f)),\n",
    "    (\"Composition\", composition(N, d, K, Q_in, Q_f_smaller)),\n",
    "    (\"Single kernel element\", single_kernel_element(N, Q_in)),\n",
    "    (\"Complex kernel element\", complex_kernel_element(N, Q_in)),\n",
    "    (\"Multiple kernels\", multiple_kernels(M, N, d, K, Q_in, Q_f_kernel)),\n",
    "    (\"Stride\", stride(N, d, K, S, Q_in, Q_f)),\n",
    "    (\"Pooling\", pooling(N, Q_in, Q_f)),\n",
    "    (\"BN\", bn(N, Q_in, Q_f)),\n",
    "    (\"Weighted kernels\", weighted_kernels(N, d, K, Q_in, Q_f)),\n",
    "    (\"Grouped kernels\", grouped_kernels(N, G, d, K, Q_in, Q_f)),\n",
    "    (\"Dilated kernels\", dilated_kernels(N, d, K, Q_in, Q_f)),\n",
    "    (\"Depthwise separable kernels\", depthwise_separable_kernels(N, d, K, Q_in, Q_f)),\n",
    "    (\"QuC with PD circuit\", quc_with_pd_circuit(N, d, K, Q_in, Q_f)),\n",
    "    (\"QuC with PD using padded kernel\", quc_with_pd_using_padded_kernel(N, d, K, Q_in, Q_f)),\n",
    "    (\"QuC with PD and pre-padded image\", quc_with_pd_and_pre_padded_image(N, d, K, Q_in, padded_Q_f)),\n",
    "    (\"Alternative QuC with PD via FTs\", alternative_quc_with_pd_via_fts(N, d, K, Q_in, Q_f))\n",
    "]\n",
    "\n",
    "time_complexities = [t[1][0] for t in techniques]\n",
    "qubit_counts = [t[1][1] for t in techniques]\n",
    "gate_counts = [t[1][2] for t in techniques]\n",
    "labels = [t[0] for t in techniques]\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 20))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "axs[0].barh(labels, time_complexities)\n",
    "axs[0].set_title('Time Complexity (Gate Operations)')\n",
    "axs[0].set_xlabel('Time Complexity')\n",
    "axs[0].set_ylabel('Technique')\n",
    "\n",
    "axs[1].barh(labels, qubit_counts)\n",
    "axs[1].set_title('Qubit Count')\n",
    "axs[1].set_xlabel('Qubit Count')\n",
    "axs[1].set_ylabel('Technique')\n",
    "\n",
    "axs[2].barh(labels, gate_counts)\n",
    "axs[2].set_title('Gate Count')\n",
    "axs[2].set_xlabel('Gate Count')\n",
    "axs[2].set_ylabel('Technique')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92981049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = cv2.imread(lenna_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if lenna_image is None:\n",
    "    raise ValueError(f\"Error loading Lenna image from path: {lenna_image_path}\")\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and process the Pepper image\n",
    "pepper_image_path = 'C:/Users/ACER/Desktop/download.jpg'\n",
    "pepper_image = cv2.imread(pepper_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if pepper_image is None:\n",
    "    raise ValueError(f\"Error loading Pepper image from path: {pepper_image_path}\")\n",
    "pepper_image = cv2.resize(pepper_image, (28, 28))\n",
    "q_pepper_image = pepper_image / 255.0\n",
    "\n",
    "# Placeholder functions for gate counts and other constants\n",
    "def gate_count(Q_in, Q_f): return Q_in * Q_f\n",
    "def gate_additional(): return 10\n",
    "def limited_gates(): return 5\n",
    "def gate_count_rotations(): return 15\n",
    "def gate_pooling(): return 20\n",
    "def gate_normalization(): return 10\n",
    "def gate_controlled_rotations(): return 25\n",
    "def gate_depthwise(): return 8\n",
    "def gate_pointwise(): return 12\n",
    "def increased_qubits_pd(): return 5\n",
    "def gate_padding(): return 7\n",
    "def gate_ft(): return 9\n",
    "def gate_conv_f(): return 11\n",
    "\n",
    "# Define the equations as functions\n",
    "def tensor_product(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, 2 * (Q_in + Q_f), 2 * gate_count(Q_in, Q_f)\n",
    "\n",
    "def composition(N, d, K, Q_in, Q_f_smaller):\n",
    "    return N**4 * d**2 * K**2, Q_in + Q_f_smaller, gate_count(Q_in, Q_f_smaller) + gate_additional()\n",
    "\n",
    "def single_kernel_element(N, Q_in):\n",
    "    return N**4, Q_in, limited_gates()\n",
    "\n",
    "def complex_kernel_element(N, Q_in):\n",
    "    return 2 * N**4, Q_in, gate_count_rotations()\n",
    "\n",
    "def multiple_kernels(M, N, d, K, Q_in, Q_f_kernel):\n",
    "    return M * N**6 * d**2 * K**2, N * (Q_in + Q_f_kernel), M * gate_count(Q_in, Q_f_kernel)\n",
    "\n",
    "def stride(N, d, K, S, Q_in, Q_f):\n",
    "    return (N**6 * d**2 * K**2) // S**2, (Q_in + Q_f // S**2), gate_count(Q_in, Q_f // S**2)\n",
    "\n",
    "def pooling(N, Q_in, Q_f):\n",
    "    return N**4, (Q_in + Q_f), gate_pooling()\n",
    "\n",
    "def bn(N, Q_in, Q_f):\n",
    "    return N**4, (Q_in + Q_f), gate_normalization()\n",
    "\n",
    "def weighted_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, 2 * (Q_in + Q_f), gate_controlled_rotations()\n",
    "\n",
    "def grouped_kernels(N, G, d, K, Q_in, Q_f):\n",
    "    return (N // G)**6 * d**2 * K**2, (N // G) * (Q_in + Q_f // G), (N // G) * gate_count(Q_in, Q_f // G)\n",
    "\n",
    "def dilated_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * (K-1)**2, (Q_in + Q_f), gate_count(Q_in, Q_f)\n",
    "\n",
    "def depthwise_separable_kernels(N, d, K, Q_in, Q_f):\n",
    "    return N**4 * d + N**2 * d * K**2, (Q_in + d * Q_f), gate_depthwise() + gate_pointwise()\n",
    "\n",
    "def quc_with_pd_circuit(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, increased_qubits_pd(), gate_padding() + gate_count(Q_in, Q_f)\n",
    "\n",
    "def quc_with_pd_using_padded_kernel(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + Q_f), gate_count(Q_in, Q_f)\n",
    "\n",
    "def quc_with_pd_and_pre_padded_image(N, d, K, Q_in, padded_Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + padded_Q_f), gate_count(Q_in, padded_Q_f)\n",
    "\n",
    "def alternative_quc_with_pd_via_fts(N, d, K, Q_in, Q_f):\n",
    "    return N**6 * d**2 * K**2, (Q_in + Q_f), gate_ft() + gate_conv_f()\n",
    "\n",
    "# Plotting the results for a specific set of parameters\n",
    "N = 28\n",
    "d = 1\n",
    "K = 3\n",
    "Q_in = 5\n",
    "Q_f = 4\n",
    "Q_f_smaller = 3\n",
    "Q_f_kernel = 2\n",
    "S = 2\n",
    "M = 1\n",
    "G = 2\n",
    "padded_Q_f = 6\n",
    "\n",
    "# Compute metrics for each image\n",
    "def compute_metrics(image_name):\n",
    "    techniques = [\n",
    "        (\"Tensor product\", tensor_product(N, d, K, Q_in, Q_f)),\n",
    "        (\"Composition\", composition(N, d, K, Q_in, Q_f_smaller)),\n",
    "        (\"Single kernel element\", single_kernel_element(N, Q_in)),\n",
    "        (\"Complex kernel element\", complex_kernel_element(N, Q_in)),\n",
    "        (\"Multiple kernels\", multiple_kernels(M, N, d, K, Q_in, Q_f_kernel)),\n",
    "        (\"Stride\", stride(N, d, K, S, Q_in, Q_f)),\n",
    "        (\"Pooling\", pooling(N, Q_in, Q_f)),\n",
    "        (\"BN\", bn(N, Q_in, Q_f)),\n",
    "        (\"Weighted kernels\", weighted_kernels(N, d, K, Q_in, Q_f)),\n",
    "        (\"Grouped kernels\", grouped_kernels(N, G, d, K, Q_in, Q_f)),\n",
    "        (\"Dilated kernels\", dilated_kernels(N, d, K, Q_in, Q_f)),\n",
    "        (\"Depthwise separable kernels\", depthwise_separable_kernels(N, d, K, Q_in, Q_f)),\n",
    "        (\"QuC with PD circuit\", quc_with_pd_circuit(N, d, K, Q_in, Q_f)),\n",
    "        (\"QuC with PD using padded kernel\", quc_with_pd_using_padded_kernel(N, d, K, Q_in, Q_f)),\n",
    "        (\"QuC with PD and pre-padded image\", quc_with_pd_and_pre_padded_image(N, d, K, Q_in, padded_Q_f)),\n",
    "        (\"Alternative QuC with PD via FTs\", alternative_quc_with_pd_via_fts(N, d, K, Q_in, Q_f))\n",
    "    ]\n",
    "    \n",
    "    time_complexities = [t[1][0] for t in techniques]\n",
    "    qubit_counts = [t[1][1] for t in techniques]\n",
    "    gate_counts = [t[1][2] for t in techniques]\n",
    "    labels = [f\"{image_name} - {t[0]}\" for t in techniques]\n",
    "    \n",
    "    return labels, time_complexities, qubit_counts, gate_counts\n",
    "\n",
    "mnist_labels, mnist_time_complexities, mnist_qubit_counts, mnist_gate_counts = compute_metrics('MNIST')\n",
    "lenna_labels, lenna_time_complexities, lenna_qubit_counts, lenna_gate_counts = compute_metrics('Lenna')\n",
    "pepper_labels, pepper_time_complexities, pepper_qubit_counts, pepper_gate_counts = compute_metrics('Pepper')\n",
    "\n",
    "# Combine all labels and metrics\n",
    "all_labels = mnist_labels + lenna_labels + pepper_labels\n",
    "all_time_complexities = mnist_time_complexities + lenna_time_complexities + pepper_time_complexities\n",
    "all_qubit_counts = mnist_qubit_counts + lenna_qubit_counts + pepper_qubit_counts\n",
    "all_gate_counts = mnist_gate_counts + lenna_gate_counts + pepper_gate_counts\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 30))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "axs[0].barh(all_labels, all_time_complexities)\n",
    "axs[0].set_title('Time Complexity (Gate Operations)')\n",
    "axs[0].set_xlabel('Time Complexity')\n",
    "axs[0].set_ylabel('Technique')\n",
    "\n",
    "axs[1].barh(all_labels, all_qubit_counts)\n",
    "axs[1].set_title('Qubit Count')\n",
    "axs[1].set_xlabel('Qubit Count')\n",
    "axs[1].set_ylabel('Technique')\n",
    "\n",
    "axs[2].barh(all_labels, all_gate_counts)\n",
    "axs[2].set_title('Gate Count')\n",
    "axs[2].set_xlabel('Gate Count')\n",
    "axs[2].set_ylabel('Technique')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd323204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "def train_and_evaluate(model, trainloader, testloader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(1):  # Use more epochs for actual training\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1, training_time, inference_time\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Run on MNIST\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mnist_metrics = train_and_evaluate(model, trainloader, testloader, device)\n",
    "\n",
    "# For simplicity, assuming similar metrics are calculated for Lenna and Pepper\n",
    "# You will need to adjust the preprocessing, model, and training methods for these images\n",
    "\n",
    "# Dummy data for Lenna and Pepper (replace with actual computations)\n",
    "lenna_metrics = (0.85, 0.84, 0.85, 0.84, 50, 0.1)  # Example values\n",
    "pepper_metrics = (0.80, 0.78, 0.79, 0.78, 55, 0.12)  # Example values\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Method': ['MNIST', 'Lenna', 'Pepper'],\n",
    "    'Accuracy': [mnist_metrics[0], lenna_metrics[0], pepper_metrics[0]],\n",
    "    'Precision': [mnist_metrics[1], lenna_metrics[1], pepper_metrics[1]],\n",
    "    'Recall': [mnist_metrics[2], lenna_metrics[2], pepper_metrics[2]],\n",
    "    'F1 Score': [mnist_metrics[3], lenna_metrics[3], pepper_metrics[3]],\n",
    "    'Training Time (s)': [mnist_metrics[4], lenna_metrics[4], pepper_metrics[4]],\n",
    "    'Inference Time (s)': [mnist_metrics[5], lenna_metrics[5], pepper_metrics[5]]\n",
    "})\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Save to CSV file\n",
    "metrics_df.to_csv('image_datasets_metrics.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Function for quantum convolution with complex kernel element\n",
    "def quantum_convolution(q_pixel, q_kernel_element, alpha=1):\n",
    "    return alpha * (q_pixel * q_kernel_element)\n",
    "\n",
    "# Initial convolution for quantum pipeline\n",
    "def initial_quantum_convolution(q_pixel, q_kernel_element):\n",
    "    return np.kron(q_pixel, q_kernel_element)\n",
    "\n",
    "# Hermitian conjugate operation\n",
    "def hermitian_conjugate(q_matrix):\n",
    "    return np.conjugate(q_matrix.T)\n",
    "\n",
    "# Quantum convolution with complex coefficient alpha\n",
    "def quantum_convolution_complex(q_pixel, q_kernel_element, alpha):\n",
    "    return alpha * quantum_convolution(q_pixel, q_kernel_element)\n",
    "\n",
    "# Function to apply Quantum Fourier Transform (QFT)\n",
    "def apply_qft(q_matrix):\n",
    "    N = q_matrix.shape[0]\n",
    "    qft_matrix = np.fft.fftshift(np.fft.fft2(q_matrix))\n",
    "    return (1 / np.sqrt(N)) * np.exp(-2j * np.pi * np.arange(N)[:, None] * np.arange(N) / N) @ qft_matrix\n",
    "\n",
    "# Function for image compression\n",
    "def image_compression(q_matrix):\n",
    "    U = np.eye(q_matrix.shape[0])  # Identity matrix for simplification\n",
    "    return U @ apply_qft(q_matrix) @ hermitian_conjugate(U)\n",
    "\n",
    "# Function to visualize quantum convolution results and their frequency graphs\n",
    "def visualize_quantum_convolution(q_image, q_kernel, alpha):\n",
    "    # Perform initial convolution\n",
    "    initial_conv = initial_quantum_convolution(q_image, q_kernel)\n",
    "\n",
    "    # Apply QFT\n",
    "    qft_result = apply_qft(initial_conv)\n",
    "\n",
    "    # Perform image compression\n",
    "    compressed_image = image_compression(initial_conv)\n",
    "\n",
    "    # Hermitian conjugate operation\n",
    "    hermitian_result = hermitian_conjugate(compressed_image)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "    # Original quantum image\n",
    "    axs[0, 0].imshow(np.abs(q_image), cmap='plasma', norm=LogNorm())\n",
    "    axs[0, 0].set_title('Original Quantum Image')\n",
    "\n",
    "    # Initial convolution\n",
    "    axs[0, 1].imshow(np.abs(initial_conv), cmap='plasma', norm=LogNorm())\n",
    "    axs[0, 1].set_title('Initial Convolution')\n",
    "\n",
    "    # QFT result\n",
    "    axs[0, 2].imshow(np.abs(qft_result), cmap='plasma', norm=LogNorm())\n",
    "    axs[0, 2].set_title('QFT Result')\n",
    "\n",
    "    # Compressed image\n",
    "    axs[0, 3].imshow(np.abs(compressed_image), cmap='plasma', norm=LogNorm())\n",
    "    axs[0, 3].set_title('Compressed Image')\n",
    "\n",
    "    # Frequency graphs\n",
    "    axs[1, 0].plot(np.abs(np.fft.fftshift(np.fft.fft2(q_image)).flatten()))\n",
    "    axs[1, 0].set_title('Frequency of Original Image')\n",
    "\n",
    "    axs[1, 1].plot(np.abs(np.fft.fftshift(np.fft.fft2(initial_conv)).flatten()))\n",
    "    axs[1, 1].set_title('Frequency of Initial Convolution')\n",
    "\n",
    "    axs[1, 2].plot(np.abs(np.fft.fftshift(np.fft.fft2(qft_result)).flatten()))\n",
    "    axs[1, 2].set_title('Frequency of QFT Result')\n",
    "\n",
    "    axs[1, 3].plot(np.abs(np.fft.fftshift(np.fft.fft2(compressed_image)).flatten()))\n",
    "    axs[1, 3].set_title('Frequency of Compressed Image')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the MNIST dataset using PyTorch\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Parameters for quantum convolution\n",
    "q_kernel_size = 3\n",
    "alpha = 1 + 1j  # Complex coefficient alpha\n",
    "\n",
    "# Generate random quantum kernel element\n",
    "q_kernel = np.random.rand(q_kernel_size, q_kernel_size) + 1j * np.random.rand(q_kernel_size, q_kernel_size)\n",
    "\n",
    "# Visualize quantum convolution results\n",
    "visualize_quantum_convolution(q_image, q_kernel, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4442ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define functions for quantum operations\n",
    "def initial_convolution(q_p, q_ki):\n",
    "    c_ij = np.random.rand(q_ki.shape[0], q_ki.shape[1])  # Random complex coefficients for kernel elements\n",
    "    d_kl = np.random.rand(q_p.shape[0], q_p.shape[1])    # Random complex coefficients for quantum image pixels\n",
    "    Qc = np.kron(c_ij, q_p) @ np.kron(d_kl, q_p)\n",
    "    return Qc\n",
    "\n",
    "def quantum_image_compression(q_i, U):\n",
    "    U_dagger = np.conjugate(U.T)\n",
    "    q_compressed = np.kron(U, q_i) @ np.kron(U_dagger, q_i)\n",
    "    return q_compressed\n",
    "\n",
    "def quantum_image_denoising(q_noisy_image, q_n, F_inv, F):\n",
    "    q_denoised = F_inv @ (F @ (q_noisy_image - q_n))\n",
    "    return q_denoised\n",
    "\n",
    "def hermitian_conjugate(Qc, q_ki, q_p):\n",
    "    q_ki_dagger = np.conjugate(q_ki.T)\n",
    "    Qc_dagger = np.kron(q_ki_dagger, q_p).T\n",
    "    return Qc_dagger\n",
    "\n",
    "def tensor_associative_property(q_ki, q_p):\n",
    "    q_ki_dagger = np.conjugate(q_ki.T)\n",
    "    result = np.kron(q_ki, q_p) @ np.kron(q_ki_dagger, np.eye(q_p.shape[0]))\n",
    "    return result\n",
    "\n",
    "# Perform Fourier Transform\n",
    "def fourier_transform(image):\n",
    "    return np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "# Load the MNIST dataset using PyTorch\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Define a sample quantum kernel\n",
    "q_ki = np.random.rand(28, 28)\n",
    "\n",
    "# Initial convolution\n",
    "initial_conv = initial_convolution(q_image, q_ki)\n",
    "\n",
    "# Quantum image compression\n",
    "U = np.random.rand(28, 28)\n",
    "compressed_image = quantum_image_compression(q_image, U)\n",
    "\n",
    "# Quantum image denoising\n",
    "F = np.random.rand(28, 28)\n",
    "F_inv = np.linalg.inv(F)\n",
    "q_noisy_image = q_image + 0.1 * np.random.rand(28, 28)  # Adding some noise\n",
    "q_n = 0.1 * np.random.rand(28, 28)  # Noise\n",
    "denoised_image = quantum_image_denoising(q_noisy_image, q_n, F_inv, F)\n",
    "\n",
    "# Hermitian conjugate\n",
    "Qc_dagger = hermitian_conjugate(initial_conv, q_ki, q_image)\n",
    "\n",
    "# Associative property of the tensor product\n",
    "associative_result = tensor_associative_property(q_ki, q_image)\n",
    "\n",
    "# Perform Fourier Transform for frequency graphs\n",
    "original_freq = np.log(np.abs(fourier_transform(q_image)) + 1)\n",
    "initial_conv_freq = np.log(np.abs(fourier_transform(initial_conv)) + 1)\n",
    "compressed_freq = np.log(np.abs(fourier_transform(compressed_image)) + 1)\n",
    "noisy_freq = np.log(np.abs(fourier_transform(q_noisy_image)) + 1)\n",
    "denoised_freq = np.log(np.abs(fourier_transform(denoised_image)) + 1)\n",
    "hermitian_conj_freq = np.log(np.abs(fourier_transform(Qc_dagger)) + 1)\n",
    "\n",
    "# Plotting the results\n",
    "fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "# Original Quantum Image\n",
    "axs[0, 0].imshow(q_image, cmap='viridis')\n",
    "axs[0, 0].set_title('Original Quantum Image')\n",
    "axs[0, 1].imshow(original_freq, cmap='viridis')\n",
    "axs[0, 1].set_title('Frequency of Original Image')\n",
    "\n",
    "# Initial Convolution\n",
    "axs[0, 2].imshow(np.abs(initial_conv), cmap='viridis')\n",
    "axs[0, 2].set_title('Initial Convolution')\n",
    "axs[0, 3].imshow(initial_conv_freq, cmap='viridis')\n",
    "axs[0, 3].set_title('Frequency of Initial Convolution')\n",
    "\n",
    "# Compressed Image\n",
    "axs[1, 0].imshow(np.abs(compressed_image), cmap='viridis')\n",
    "axs[1, 0].set_title('Compressed Image')\n",
    "axs[1, 1].imshow(compressed_freq, cmap='viridis')\n",
    "axs[1, 1].set_title('Frequency of Compressed Image')\n",
    "\n",
    "# Noisy Quantum Image\n",
    "axs[1, 2].imshow(np.abs(q_noisy_image), cmap='viridis')\n",
    "axs[1, 2].set_title('Noisy Quantum Image')\n",
    "axs[1, 3].imshow(noisy_freq, cmap='viridis')\n",
    "axs[1, 3].set_title('Frequency of Noisy Image')\n",
    "\n",
    "# Denoised Quantum Image\n",
    "axs[2, 0].imshow(np.abs(denoised_image), cmap='viridis')\n",
    "axs[2, 0].set_title('Denoised Quantum Image')\n",
    "axs[2, 1].imshow(denoised_freq, cmap='viridis')\n",
    "axs[2, 1].set_title('Frequency of Denoised Image')\n",
    "\n",
    "# Hermitian Conjugate Result\n",
    "axs[2, 2].imshow(np.abs(Qc_dagger), cmap='viridis')\n",
    "axs[2, 2].set_title('Hermitian Conjugate')\n",
    "axs[2, 3].imshow(hermitian_conj_freq, cmap='viridis')\n",
    "axs[2, 3].set_title('Frequency of Hermitian Conjugate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab530a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenCV\n",
    "!pip install opencv-python\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Define functions for quantum operations\n",
    "def initial_convolution(q_p, q_ki):\n",
    "    c_ij = np.random.rand(q_ki.shape[0], q_ki.shape[1])  # Random complex coefficients for kernel elements\n",
    "    d_kl = np.random.rand(q_p.shape[0], q_p.shape[1])    # Random complex coefficients for quantum image pixels\n",
    "    Qc = np.kron(c_ij, q_p) @ np.kron(d_kl, q_p)\n",
    "    return Qc\n",
    "\n",
    "def quantum_image_compression(q_i, U):\n",
    "    U_dagger = np.conjugate(U.T)\n",
    "    q_compressed = np.kron(U, q_i) @ np.kron(U_dagger, q_i)\n",
    "    return q_compressed\n",
    "\n",
    "def quantum_image_denoising(q_noisy_image, q_n, F_inv, F):\n",
    "    q_denoised = F_inv @ (F @ (q_noisy_image - q_n))\n",
    "    return q_denoised\n",
    "\n",
    "def hermitian_conjugate(Qc, q_ki, q_p):\n",
    "    q_ki_dagger = np.conjugate(q_ki.T)\n",
    "    Qc_dagger = np.kron(q_ki_dagger, q_p).T\n",
    "    return Qc_dagger\n",
    "\n",
    "def tensor_associative_property(q_ki, q_p):\n",
    "    q_ki_dagger = np.conjugate(q_ki.T)\n",
    "    result = np.kron(q_ki, q_p) @ np.kron(q_ki_dagger, np.eye(q_p.shape[0]))\n",
    "    return result\n",
    "\n",
    "# Perform Fourier Transform\n",
    "def fourier_transform(image):\n",
    "    return np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "# Load the MNIST dataset using PyTorch\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Load the Lenna image\n",
    "lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0  # Normalize the image\n",
    "\n",
    "# Define a sample quantum kernel\n",
    "q_ki = np.random.rand(28, 28)\n",
    "\n",
    "# Initial convolution for MNIST image\n",
    "initial_conv_mnist = initial_convolution(q_image, q_ki)\n",
    "\n",
    "# Initial convolution for Lenna image\n",
    "initial_conv_lenna = initial_convolution(q_lenna_image, q_ki)\n",
    "\n",
    "# Quantum image compression for MNIST image\n",
    "U = np.random.rand(28, 28)\n",
    "compressed_image_mnist = quantum_image_compression(q_image, U)\n",
    "\n",
    "# Quantum image compression for Lenna image\n",
    "compressed_image_lenna = quantum_image_compression(q_lenna_image, U)\n",
    "\n",
    "# Quantum image denoising for MNIST image\n",
    "F = np.random.rand(28, 28)\n",
    "F_inv = np.linalg.inv(F)\n",
    "q_noisy_image_mnist = q_image + 0.1 * np.random.rand(28, 28)  # Adding some noise\n",
    "q_n = 0.1 * np.random.rand(28, 28)  # Noise\n",
    "denoised_image_mnist = quantum_image_denoising(q_noisy_image_mnist, q_n, F_inv, F)\n",
    "\n",
    "# Quantum image denoising for Lenna image\n",
    "q_noisy_image_lenna = q_lenna_image + 0.1 * np.random.rand(28, 28)  # Adding some noise\n",
    "denoised_image_lenna = quantum_image_denoising(q_noisy_image_lenna, q_n, F_inv, F)\n",
    "\n",
    "# Hermitian conjugate for MNIST image\n",
    "Qc_dagger_mnist = hermitian_conjugate(initial_conv_mnist, q_ki, q_image)\n",
    "\n",
    "# Hermitian conjugate for Lenna image\n",
    "Qc_dagger_lenna = hermitian_conjugate(initial_conv_lenna, q_ki, q_lenna_image)\n",
    "\n",
    "# Associative property of the tensor product for MNIST image\n",
    "associative_result_mnist = tensor_associative_property(q_ki, q_image)\n",
    "\n",
    "# Associative property of the tensor product for Lenna image\n",
    "associative_result_lenna = tensor_associative_property(q_ki, q_lenna_image)\n",
    "\n",
    "# Perform Fourier Transform for frequency graphs\n",
    "original_freq_mnist = np.log(np.abs(fourier_transform(q_image)) + 1)\n",
    "initial_conv_freq_mnist = np.log(np.abs(fourier_transform(initial_conv_mnist)) + 1)\n",
    "compressed_freq_mnist = np.log(np.abs(fourier_transform(compressed_image_mnist)) + 1)\n",
    "noisy_freq_mnist = np.log(np.abs(fourier_transform(q_noisy_image_mnist)) + 1)\n",
    "denoised_freq_mnist = np.log(np.abs(fourier_transform(denoised_image_mnist)) + 1)\n",
    "hermitian_conj_freq_mnist = np.log(np.abs(fourier_transform(Qc_dagger_mnist)) + 1)\n",
    "\n",
    "original_freq_lenna = np.log(np.abs(fourier_transform(q_lenna_image)) + 1)\n",
    "initial_conv_freq_lenna = np.log(np.abs(fourier_transform(initial_conv_lenna)) + 1)\n",
    "compressed_freq_lenna = np.log(np.abs(fourier_transform(compressed_image_lenna)) + 1)\n",
    "noisy_freq_lenna = np.log(np.abs(fourier_transform(q_noisy_image_lenna)) + 1)\n",
    "denoised_freq_lenna = np.log(np.abs(fourier_transform(denoised_image_lenna)) + 1)\n",
    "hermitian_conj_freq_lenna = np.log(np.abs(fourier_transform(Qc_dagger_lenna)) + 1)\n",
    "\n",
    "# Plotting the results\n",
    "fig, axs = plt.subplots(6, 4, figsize=(20, 30))\n",
    "\n",
    "# Original MNIST Quantum Image\n",
    "axs[0, 0].imshow(q_image, cmap='viridis')\n",
    "axs[0, 0].set_title('Original MNIST Quantum Image')\n",
    "axs[0, 1].imshow(original_freq_mnist, cmap='viridis')\n",
    "axs[0, 1].set_title('Frequency of Original MNIST Image')\n",
    "\n",
    "# Initial Convolution for MNIST image\n",
    "axs[0, 2].imshow(np.abs(initial_conv_mnist), cmap='viridis')\n",
    "axs[0, 2].set_title('Initial Convolution (MNIST)')\n",
    "axs[0, 3].imshow(initial_conv_freq_mnist, cmap='viridis')\n",
    "axs[0, 3].set_title('Frequency of Initial Convolution (MNIST)')\n",
    "\n",
    "# Compressed MNIST Image\n",
    "axs[1, 0].imshow(np.abs(compressed_image_mnist), cmap='viridis')\n",
    "axs[1, 0].set_title('Compressed MNIST Image')\n",
    "axs[1, 1].imshow(compressed_freq_mnist, cmap='viridis')\n",
    "axs[1, 1].set_title('Frequency of Compressed MNIST Image')\n",
    "\n",
    "# Noisy MNIST Quantum Image\n",
    "axs[1, 2].imshow(np.abs(q_noisy_image_mnist), cmap='viridis')\n",
    "axs[1, 2].set_title('Noisy MNIST Quantum Image')\n",
    "axs[1, 3].imshow(noisy_freq_mnist, cmap='viridis')\n",
    "axs[1, 3].set_title('Frequency of Noisy MNIST Image')\n",
    "\n",
    "# Denoised MNIST Quantum Image\n",
    "axs[2, 0].imshow(np.abs(denoised_image_mnist), cmap='viridis')\n",
    "axs[2, 0].set_title('Denoised MNIST Quantum Image')\n",
    "axs[2, 1].imshow(denoised_freq_mnist, cmap='viridis')\n",
    "axs[2, 1].set_title('Frequency of Denoised MNIST Image')\n",
    "\n",
    "# Hermitian Conjugate for MNIST image\n",
    "axs[2, 2].imshow(np.abs(Qc_dagger_mnist), cmap='viridis')\n",
    "axs[2, 2].set_title('Hermitian Conjugate (MNIST)')\n",
    "axs[2, 3].imshow(hermitian_conj_freq_mnist, cmap='viridis')\n",
    "axs[2, 3].set_title('Frequency of Hermitian Conjugate (MNIST)')\n",
    "\n",
    "# Original Lenna Quantum Image\n",
    "axs[3, 0].imshow(q_lenna_image, cmap='viridis')\n",
    "axs[3, 0].set_title('Original Lenna Quantum Image')\n",
    "axs[3, 1].imshow(original_freq_lenna, cmap='viridis')\n",
    "axs[3, 1].set_title('Frequency of Original Lenna Image')\n",
    "\n",
    "# Initial Convolution for Lenna image\n",
    "axs[3, 2].imshow(np.abs(initial_conv_lenna), cmap='viridis')\n",
    "axs[3, 2].set_title('Initial Convolution (Lenna)')\n",
    "axs[3, 3].imshow(initial_conv_freq_lenna, cmap='viridis')\n",
    "axs[3, 3].set_title('Frequency of Initial Convolution (Lenna)')\n",
    "\n",
    "# Compressed Lenna Image\n",
    "axs[4, 0].imshow(np.abs(compressed_image_lenna), cmap='viridis')\n",
    "axs[4, 0].set_title('Compressed Lenna Image')\n",
    "axs[4, 1].imshow(compressed_freq_lenna, cmap='viridis')\n",
    "axs[4, 1].set_title('Frequency of Compressed Lenna Image')\n",
    "\n",
    "# Noisy Lenna Quantum Image\n",
    "axs[4, 2].imshow(np.abs(q_noisy_image_lenna), cmap='viridis')\n",
    "axs[4, 2].set_title('Noisy Lenna Quantum Image')\n",
    "axs[4, 3].imshow(noisy_freq_lenna, cmap='viridis')\n",
    "axs[4, 3].set_title('Frequency of Noisy Lenna Image')\n",
    "\n",
    "# Denoised Lenna Quantum Image\n",
    "axs[5, 0].imshow(np.abs(denoised_image_lenna), cmap='viridis')\n",
    "axs[5, 0].set_title('Denoised Lenna Quantum Image')\n",
    "axs[5, 1].imshow(denoised_freq_lenna, cmap='viridis')\n",
    "axs[5, 1].set_title('Frequency of Denoised Lenna Image')\n",
    "\n",
    "# Hermitian Conjugate for Lenna image\n",
    "axs[5, 2].imshow(np.abs(Qc_dagger_lenna), cmap='viridis')\n",
    "axs[5, 2].set_title('Hermitian Conjugate (Lenna)')\n",
    "axs[5, 3].imshow(hermitian_conj_freq_lenna, cmap='viridis')\n",
    "axs[5, 3].set_title('Frequency of Hermitian Conjugate (Lenna)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def quantum_convolution(q_i, q_kernels, alpha, beta):\n",
    "    n = len(q_kernels)\n",
    "    Qc_sum = np.zeros_like(q_i, dtype=np.complex128)\n",
    "    for m in range(n):\n",
    "        kernel = q_kernels[m]\n",
    "        alpha_m = alpha[m]\n",
    "        beta_m = beta[m]\n",
    "        kernel_size = kernel.shape\n",
    "        padded_image = np.pad(q_i, [(kernel_size[0]//2, kernel_size[0]//2), (kernel_size[1]//2, kernel_size[1]//2)], mode='constant')\n",
    "        conv_result = np.zeros_like(q_i, dtype=np.complex128)\n",
    "        for i in range(q_i.shape[0]):\n",
    "            for j in range(q_i.shape[1]):\n",
    "                conv_result[i, j] = np.sum(\n",
    "                    padded_image[i:i+kernel_size[0], j:j+kernel_size[1]] * kernel\n",
    "                )\n",
    "        Qc_sum += alpha_m * beta_m * conv_result\n",
    "    return Qc_sum\n",
    "\n",
    "def quantum_convolution_stride(q_i, q_k, stride):\n",
    "    q_i_stride = q_i[::stride, ::stride]\n",
    "    kernel_size = q_k.shape[0]\n",
    "    padded_image = np.pad(q_i_stride, [(kernel_size//2, kernel_size//2), (kernel_size//2, kernel_size//2)], mode='constant')\n",
    "    Qc_stride = np.zeros_like(q_i_stride, dtype=np.complex128)\n",
    "    for i in range(q_i_stride.shape[0]):\n",
    "        for j in range(q_i_stride.shape[1]):\n",
    "            Qc_stride[i, j] = np.sum(\n",
    "                padded_image[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_stride\n",
    "\n",
    "def pad_image(q_i, pad_width):\n",
    "    return np.pad(q_i, pad_width, mode='constant')\n",
    "\n",
    "def quantum_convolution_pad(q_i, q_k, pad_width):\n",
    "    q_i_padded = pad_image(q_i, ((pad_width, pad_width), (pad_width, pad_width)))\n",
    "    kernel_size = q_k.shape[0]\n",
    "    Qc_pad = np.zeros_like(q_i_padded, dtype=np.complex128)\n",
    "    for i in range(q_i.shape[0]):\n",
    "        for j in range(q_i.shape[1]):\n",
    "            Qc_pad[i, j] = np.sum(\n",
    "                q_i_padded[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_pad\n",
    "\n",
    "def batch_norm(q_i, epsilon=1e-5):\n",
    "    mu = np.mean(q_i)\n",
    "    sigma2 = np.var(q_i)\n",
    "    q_bn = (q_i - mu) / np.sqrt(sigma2 + epsilon)\n",
    "    return q_bn\n",
    "\n",
    "def quantum_convolution_bn(q_i, q_k, stride, pool_size):\n",
    "    q_i_bn = batch_norm(q_i)\n",
    "    q_i_pooled = q_i_bn[:pool_size, :pool_size]\n",
    "    Qc_bn_pool = quantum_convolution_stride(q_i_pooled, q_k, stride)\n",
    "    return Qc_bn_pool\n",
    "\n",
    "def fourier_transform(image):\n",
    "    return np.fft.fftshift(np.fft.fft2(image))\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "q_kernels = [np.random.rand(3, 3) for _ in range(3)]\n",
    "alpha = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "beta = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "\n",
    "qc_mnist = quantum_convolution(q_image, q_kernels, alpha, beta)\n",
    "qc_stride_mnist = quantum_convolution_stride(q_image, q_kernels[0], stride=2)\n",
    "qc_pad_mnist = quantum_convolution_pad(q_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_mnist = quantum_convolution_bn(q_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "qc_lenna = quantum_convolution(q_lenna_image, q_kernels, alpha, beta)\n",
    "qc_stride_lenna = quantum_convolution_stride(q_lenna_image, q_kernels[0], stride=2)\n",
    "qc_pad_lenna = quantum_convolution_pad(q_lenna_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_lenna = quantum_convolution_bn(q_lenna_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(20, 20))\n",
    "\n",
    "axs[0, 0].imshow(q_image, cmap='viridis')\n",
    "axs[0, 0].set_title('Original MNIST Quantum Image')\n",
    "axs[0, 1].imshow(q_lenna_image, cmap='viridis')\n",
    "axs[0, 1].set_title('Original Lenna Image')\n",
    "\n",
    "axs[1, 0].imshow(np.abs(qc_mnist), cmap='viridis')\n",
    "axs[1, 0].set_title('Quantum Convolution with Multiple Kernels (MNIST)')\n",
    "axs[1, 1].imshow(np.abs(qc_lenna), cmap='viridis')\n",
    "axs[1, 1].set_title('Quantum Convolution with Multiple Kernels (Lenna)')\n",
    "\n",
    "axs[2, 0].imshow(np.abs(qc_stride_mnist), cmap='viridis')\n",
    "axs[2, 0].set_title('Quantum Convolution with Stride (MNIST)')\n",
    "axs[2, 1].imshow(np.abs(qc_stride_lenna), cmap='viridis')\n",
    "axs[2, 1].set_title('Quantum Convolution with Stride (Lenna)')\n",
    "\n",
    "axs[3, 0].imshow(np.abs(qc_pad_mnist), cmap='viridis')\n",
    "axs[3, 0].set_title('Quantum Convolution with Padding (MNIST)')\n",
    "axs[3, 1].imshow(np.abs(qc_pad_lenna), cmap='viridis')\n",
    "axs[3, 1].set_title('Quantum Convolution with Padding (Lenna)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def quantum_convolution(q_i, q_kernels, alpha, beta):\n",
    "    n = len(q_kernels)\n",
    "    Qc_sum = np.zeros_like(q_i, dtype=np.complex128)\n",
    "    for m in range(n):\n",
    "        kernel = q_kernels[m]\n",
    "        alpha_m = alpha[m]\n",
    "        beta_m = beta[m]\n",
    "        kernel_size = kernel.shape\n",
    "        padded_image = np.pad(q_i, [(kernel_size[0]//2, kernel_size[0]//2), (kernel_size[1]//2, kernel_size[1]//2)], mode='constant')\n",
    "        conv_result = np.zeros_like(q_i, dtype=np.complex128)\n",
    "        for i in range(q_i.shape[0]):\n",
    "            for j in range(q_i.shape[1]):\n",
    "                conv_result[i, j] = np.sum(\n",
    "                    padded_image[i:i+kernel_size[0], j:j+kernel_size[1]] * kernel\n",
    "                )\n",
    "        Qc_sum += alpha_m * beta_m * conv_result\n",
    "    return Qc_sum\n",
    "\n",
    "def quantum_convolution_stride(q_i, q_k, stride):\n",
    "    q_i_stride = q_i[::stride, ::stride]\n",
    "    kernel_size = q_k.shape[0]\n",
    "    padded_image = np.pad(q_i_stride, [(kernel_size//2, kernel_size//2), (kernel_size//2, kernel_size//2)], mode='constant')\n",
    "    Qc_stride = np.zeros_like(q_i_stride, dtype=np.complex128)\n",
    "    for i in range(q_i_stride.shape[0]):\n",
    "        for j in range(q_i_stride.shape[1]):\n",
    "            Qc_stride[i, j] = np.sum(\n",
    "                padded_image[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_stride\n",
    "\n",
    "def pad_image(q_i, pad_width):\n",
    "    return np.pad(q_i, pad_width, mode='constant')\n",
    "\n",
    "def quantum_convolution_pad(q_i, q_k, pad_width):\n",
    "    q_i_padded = pad_image(q_i, ((pad_width, pad_width), (pad_width, pad_width)))\n",
    "    kernel_size = q_k.shape[0]\n",
    "    Qc_pad = np.zeros_like(q_i_padded, dtype=np.complex128)\n",
    "    for i in range(q_i.shape[0]):\n",
    "        for j in range(q_i.shape[1]):\n",
    "            Qc_pad[i, j] = np.sum(\n",
    "                q_i_padded[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_pad\n",
    "\n",
    "def batch_norm(q_i, epsilon=1e-5):\n",
    "    mu = np.mean(q_i)\n",
    "    sigma2 = np.var(q_i)\n",
    "    q_bn = (q_i - mu) / np.sqrt(sigma2 + epsilon)\n",
    "    return q_bn\n",
    "\n",
    "def quantum_convolution_bn(q_i, q_k, stride, pool_size):\n",
    "    q_i_bn = batch_norm(q_i)\n",
    "    q_i_pooled = q_i_bn[:pool_size, :pool_size]\n",
    "    Qc_bn_pool = quantum_convolution_stride(q_i_pooled, q_k, stride)\n",
    "    return Qc_bn_pool\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "download_image = cv2.imread('C:/Users/ACER/Desktop/download.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "download_image = cv2.resize(download_image, (28, 28))\n",
    "q_download_image = download_image / 255.0\n",
    "\n",
    "q_kernels = [np.random.rand(3, 3) for _ in range(3)]\n",
    "alpha = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "beta = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "\n",
    "qc_mnist = quantum_convolution(q_image, q_kernels, alpha, beta)\n",
    "qc_stride_mnist = quantum_convolution_stride(q_image, q_kernels[0], stride=2)\n",
    "qc_pad_mnist = quantum_convolution_pad(q_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_mnist = quantum_convolution_bn(q_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "qc_lenna = quantum_convolution(q_lenna_image, q_kernels, alpha, beta)\n",
    "qc_stride_lenna = quantum_convolution_stride(q_lenna_image, q_kernels[0], stride=2)\n",
    "qc_pad_lenna = quantum_convolution_pad(q_lenna_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_lenna = quantum_convolution_bn(q_lenna_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "qc_download = quantum_convolution(q_download_image, q_kernels, alpha, beta)\n",
    "qc_stride_download = quantum_convolution_stride(q_download_image, q_kernels[0], stride=2)\n",
    "qc_pad_download = quantum_convolution_pad(q_download_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_download = quantum_convolution_bn(q_download_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "axs[0, 0].imshow(q_image, cmap='viridis')\n",
    "axs[0, 0].set_title('Original MNIST Quantum Image')\n",
    "axs[0, 1].imshow(np.abs(qc_mnist), cmap='viridis')\n",
    "axs[0, 1].set_title('Quantum Convolution with Multiple Kernels (MNIST)')\n",
    "axs[0, 2].imshow(np.abs(qc_stride_mnist), cmap='viridis')\n",
    "axs[0, 2].set_title('Quantum Convolution with Stride (MNIST)')\n",
    "axs[0, 3].imshow(np.abs(qc_pad_mnist), cmap='viridis')\n",
    "axs[0, 3].set_title('Quantum Convolution with Padding (MNIST)')\n",
    "\n",
    "axs[1, 0].imshow(q_lenna_image, cmap='viridis')\n",
    "axs[1, 0].set_title('Original Lenna Image')\n",
    "axs[1, 1].imshow(np.abs(qc_lenna), cmap='viridis')\n",
    "axs[1, 1].set_title('Quantum Convolution with Multiple Kernels (Lenna)')\n",
    "axs[1, 2].imshow(np.abs(qc_stride_lenna), cmap='viridis')\n",
    "axs[1, 2].set_title('Quantum Convolution with Stride (Lenna)')\n",
    "axs[1, 3].imshow(np.abs(qc_pad_lenna), cmap='viridis')\n",
    "axs[1, 3].set_title('Quantum Convolution with Padding (Lenna)')\n",
    "\n",
    "axs[2, 0].imshow(q_download_image, cmap='viridis')\n",
    "axs[2, 0].set_title('Original Download Image')\n",
    "axs[2, 1].imshow(np.abs(qc_download), cmap='viridis')\n",
    "axs[2, 1].set_title('Quantum Convolution with Multiple Kernels (Download)')\n",
    "axs[2, 2].imshow(np.abs(qc_stride_download), cmap='viridis')\n",
    "axs[2, 2].set_title('Quantum Convolution with Stride (Download)')\n",
    "axs[2, 3].imshow(np.abs(qc_pad_download), cmap='viridis')\n",
    "axs[2, 3].set_title('Quantum Convolution with Padding (Download)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Function for quantum convolution with multiple kernels\n",
    "def quantum_convolution(q_i, q_kernels, alpha, beta):\n",
    "    n = len(q_kernels)\n",
    "    Qc_sum = np.zeros_like(q_i, dtype=np.complex128)\n",
    "    for m in range(n):\n",
    "        kernel = q_kernels[m]\n",
    "        alpha_m = alpha[m]\n",
    "        beta_m = beta[m]\n",
    "        kernel_size = kernel.shape\n",
    "        padded_image = np.pad(q_i, [(kernel_size[0]//2, kernel_size[0]//2), (kernel_size[1]//2, kernel_size[1]//2)], mode='constant')\n",
    "        conv_result = np.zeros_like(q_i, dtype=np.complex128)\n",
    "        for i in range(q_i.shape[0]):\n",
    "            for j in range(q_i.shape[1]):\n",
    "                conv_result[i, j] = np.sum(\n",
    "                    padded_image[i:i+kernel_size[0], j:j+kernel_size[1]] * kernel\n",
    "                )\n",
    "        Qc_sum += alpha_m * beta_m * conv_result\n",
    "    return Qc_sum\n",
    "\n",
    "# Function for quantum convolution with stride\n",
    "def quantum_convolution_stride(q_i, q_k, stride):\n",
    "    q_i_stride = q_i[::stride, ::stride]\n",
    "    kernel_size = q_k.shape[0]\n",
    "    padded_image = np.pad(q_i_stride, [(kernel_size//2, kernel_size//2), (kernel_size//2, kernel_size//2)], mode='constant')\n",
    "    Qc_stride = np.zeros_like(q_i_stride, dtype=np.complex128)\n",
    "    for i in range(q_i_stride.shape[0]):\n",
    "        for j in range(q_i_stride.shape[1]):\n",
    "            Qc_stride[i, j] = np.sum(\n",
    "                padded_image[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_stride\n",
    "\n",
    "# Function for padding image\n",
    "def pad_image(q_i, pad_width):\n",
    "    return np.pad(q_i, pad_width, mode='constant')\n",
    "\n",
    "# Function for quantum convolution with padding\n",
    "def quantum_convolution_pad(q_i, q_k, pad_width):\n",
    "    q_i_padded = pad_image(q_i, ((pad_width, pad_width), (pad_width, pad_width)))\n",
    "    kernel_size = q_k.shape[0]\n",
    "    Qc_pad = np.zeros_like(q_i_padded, dtype=np.complex128)\n",
    "    for i in range(q_i.shape[0]):\n",
    "        for j in range(q_i.shape[1]):\n",
    "            Qc_pad[i, j] = np.sum(\n",
    "                q_i_padded[i:i+kernel_size, j:j+kernel_size] * q_k\n",
    "            )\n",
    "    return Qc_pad\n",
    "\n",
    "# Function for batch normalization\n",
    "def batch_norm(q_i, epsilon=1e-5):\n",
    "    mu = np.mean(q_i)\n",
    "    sigma2 = np.var(q_i)\n",
    "    q_bn = (q_i - mu) / np.sqrt(sigma2 + epsilon)\n",
    "    return q_bn\n",
    "\n",
    "# Function for quantum convolution with batch normalization and pooling\n",
    "def quantum_convolution_bn(q_i, q_k, stride, pool_size):\n",
    "    q_i_bn = batch_norm(q_i)\n",
    "    q_i_pooled = q_i_bn[:pool_size, :pool_size]\n",
    "    Qc_bn_pool = quantum_convolution_stride(q_i_pooled, q_k, stride)\n",
    "    return Qc_bn_pool\n",
    "\n",
    "# Data transformations for MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Load and preprocess Lenna image\n",
    "lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and preprocess download image\n",
    "download_image = cv2.imread('C:/Users/ACER/Desktop/download.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "download_image = cv2.resize(download_image, (28, 28))\n",
    "q_download_image = download_image / 255.0\n",
    "\n",
    "# Define quantum kernels and coefficients\n",
    "q_kernels = [np.random.rand(3, 3) for _ in range(3)]\n",
    "alpha = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "beta = [np.random.rand() + 1j * np.random.rand() for _ in range(3)]\n",
    "\n",
    "# Apply quantum convolution methods\n",
    "qc_mnist = quantum_convolution(q_image, q_kernels, alpha, beta)\n",
    "qc_stride_mnist = quantum_convolution_stride(q_image, q_kernels[0], stride=2)\n",
    "qc_pad_mnist = quantum_convolution_pad(q_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_mnist = quantum_convolution_bn(q_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "qc_lenna = quantum_convolution(q_lenna_image, q_kernels, alpha, beta)\n",
    "qc_stride_lenna = quantum_convolution_stride(q_lenna_image, q_kernels[0], stride=2)\n",
    "qc_pad_lenna = quantum_convolution_pad(q_lenna_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_lenna = quantum_convolution_bn(q_lenna_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "qc_download = quantum_convolution(q_download_image, q_kernels, alpha, beta)\n",
    "qc_stride_download = quantum_convolution_stride(q_download_image, q_kernels[0], stride=2)\n",
    "qc_pad_download = quantum_convolution_pad(q_download_image, q_kernels[0], pad_width=2)\n",
    "qc_bn_pool_download = quantum_convolution_bn(q_download_image, q_kernels[0], stride=2, pool_size=14)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(3, 5, figsize=(24, 15))\n",
    "\n",
    "# Plot MNIST results\n",
    "axs[0, 0].imshow(q_image, cmap='viridis')\n",
    "axs[0, 0].set_title('Original MNIST Quantum Image')\n",
    "axs[0, 1].imshow(np.abs(qc_mnist), cmap='viridis')\n",
    "axs[0, 1].set_title('Quantum Convolution with Multiple Kernels (MNIST)')\n",
    "axs[0, 2].imshow(np.abs(qc_stride_mnist), cmap='viridis')\n",
    "axs[0, 2].set_title('Quantum Convolution with Stride (MNIST)')\n",
    "axs[0, 3].imshow(np.abs(qc_pad_mnist), cmap='viridis')\n",
    "axs[0, 3].set_title('Quantum Convolution with Padding (MNIST)')\n",
    "axs[0, 4].imshow(np.abs(qc_bn_pool_mnist), cmap='viridis')\n",
    "axs[0, 4].set_title('Quantum Convolution with BN (MNIST)')\n",
    "\n",
    "# Plot Lenna results\n",
    "axs[1, 0].imshow(q_lenna_image, cmap='viridis')\n",
    "axs[1, 0].set_title('Original Lenna Image')\n",
    "axs[1, 1].imshow(np.abs(qc_lenna), cmap='viridis')\n",
    "axs[1, 1].set_title('Quantum Convolution with Multiple Kernels (Lenna)')\n",
    "axs[1, 2].imshow(np.abs(qc_stride_lenna), cmap='viridis')\n",
    "axs[1, 2].set_title('Quantum Convolution with Stride (Lenna)')\n",
    "axs[1, 3].imshow(np.abs(qc_pad_lenna), cmap='viridis')\n",
    "axs[1, 3].set_title('Quantum Convolution with Padding (Lenna)')\n",
    "axs[1, 4].imshow(np.abs(qc_bn_pool_lenna), cmap='viridis')\n",
    "axs[1, 4].set_title('Quantum Convolution with BN (Lenna)')\n",
    "\n",
    "# Plot Download image results\n",
    "axs[2, 0].imshow(q_download_image, cmap='viridis')\n",
    "axs[2, 0].set_title('Original Pepper Image')\n",
    "axs[2, 1].imshow(np.abs(qc_download), cmap='viridis')\n",
    "axs[2, 1].set_title('Quantum Convolution with Multiple Kernels')\n",
    "axs[2, 2].imshow(np.abs(qc_stride_download), cmap='viridis')\n",
    "axs[2, 2].set_title('Quantum Convolution with Stride')\n",
    "axs[2, 3].imshow(np.abs(qc_pad_download), cmap='viridis')\n",
    "axs[2, 3].set_title('Quantum Convolution with Padding')\n",
    "axs[2, 4].imshow(np.abs(qc_bn_pool_download), cmap='viridis')\n",
    "axs[2, 4].set_title('Quantum Convolution with BN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"quantum_image_processing.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270dd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the quantum convolution function with weights\n",
    "def quantum_convolution_weighted(q_i, q_k_list, weights):\n",
    "    result = torch.zeros_like(q_i)\n",
    "    for q_k, weight in zip(q_k_list, weights):\n",
    "        padding = (q_k.shape[-1] // 2, q_k.shape[-2] // 2)\n",
    "        result += weight * F.conv2d(q_i, q_k, padding=padding)\n",
    "    return result\n",
    "\n",
    "# Plot the original and processed images\n",
    "def plot_images(original, processed, title):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(original.squeeze(), cmap='gray')\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[1].imshow(processed.squeeze().detach().numpy(), cmap='gray')\n",
    "    axs[1].set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Main function to apply quantum convolution\n",
    "def main():\n",
    "    # Load the MNIST dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "    mnist_image, _ = trainset[0]\n",
    "    q_mnist_image = mnist_image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Load and process the Lenna image\n",
    "    lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "    q_lenna_image = torch.tensor(lenna_image / 255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel and batch dimensions\n",
    "\n",
    "    # Load and process the download image\n",
    "    download_image = cv2.imread('C:/Users/ACER/Desktop/download.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    download_image = cv2.resize(download_image, (28, 28))\n",
    "    q_download_image = torch.tensor(download_image / 255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel and batch dimensions\n",
    "\n",
    "    # Define quantum kernels\n",
    "    kernel_1 = torch.randn(1, 1, 3, 3)  # Example kernel\n",
    "    kernel_2 = torch.randn(1, 1, 3, 3)  # Example kernel\n",
    "    kernel_3 = torch.randn(1, 1, 3, 3)  # Example kernel\n",
    "\n",
    "    # Define weights\n",
    "    weights = [0.2, 0.3, 0.5]\n",
    "\n",
    "    # Apply quantum convolution with weighted kernels to MNIST image\n",
    "    processed_mnist_weighted = quantum_convolution_weighted(q_mnist_image, [kernel_1, kernel_2, kernel_3], weights)\n",
    "    plot_images(q_mnist_image.squeeze(), processed_mnist_weighted, 'Weighted Quantum Convolution (MNIST)')\n",
    "\n",
    "    # Apply quantum convolution with weighted kernels to Lenna image\n",
    "    processed_lenna_weighted = quantum_convolution_weighted(q_lenna_image, [kernel_1, kernel_2, kernel_3], weights)\n",
    "    plot_images(q_lenna_image.squeeze(), processed_lenna_weighted, 'Weighted Quantum Convolution (Lenna)')\n",
    "\n",
    "    # Apply quantum convolution with weighted kernels to download image\n",
    "    processed_download_weighted = quantum_convolution_weighted(q_download_image, [kernel_1, kernel_2, kernel_3], weights)\n",
    "    plot_images(q_download_image.squeeze(), processed_download_weighted, 'Weighted Quantum Convolution (Download)')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3af34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "\n",
    "# Define the transform for the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image = cv2.imread('C:/Users/ACER/Desktop/lena_256.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and process another image\n",
    "download_image = cv2.imread('C:/Users/ACER/Desktop/download.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "download_image = cv2.resize(download_image, (28, 28))\n",
    "q_download_image = download_image / 255.0\n",
    "\n",
    "# Define a function to apply the weighted quantum convolution\n",
    "def quantum_convolution_weighted(q_i, q_k, weights):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for k, w in zip(q_k, weights):\n",
    "        result += w * (k * q_i)\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the separable quantum convolution\n",
    "def quantum_convolution_separable(q_i, q_kx, q_ky):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for kx, ky in zip(q_kx, q_ky):\n",
    "        result += np.outer(kx, ky) * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the dilated quantum convolution\n",
    "def quantum_convolution_dilated(q_i, q_k, d):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for k in q_k:\n",
    "        dilated_k = cv2.dilate(k, np.ones((d, d), np.uint8))\n",
    "        result += dilated_k * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the grouped quantum convolution\n",
    "def quantum_convolution_grouped(q_i, q_kgroups):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for group in q_kgroups:\n",
    "        group_result = np.zeros_like(q_i)\n",
    "        for k in group:\n",
    "            group_result += k * q_i\n",
    "        result += group_result\n",
    "    return result\n",
    "\n",
    "# Example kernels and weights\n",
    "kernels = [np.random.rand(28, 28) for _ in range(3)]\n",
    "weights = [0.3, 0.5, 0.2]\n",
    "kx = [np.random.rand(28) for _ in range(3)]\n",
    "ky = [np.random.rand(28) for _ in range(3)]\n",
    "groups = [[np.random.rand(28, 28) for _ in range(2)], [np.random.rand(28, 28) for _ in range(2)]]\n",
    "dilation_rate = 2\n",
    "\n",
    "# Apply the quantum convolution operations to the MNIST image\n",
    "q_weighted = quantum_convolution_weighted(q_image, kernels, weights)\n",
    "q_separable = quantum_convolution_separable(q_image, kx, ky)\n",
    "q_dilated = quantum_convolution_dilated(q_image, kernels, dilation_rate)\n",
    "q_grouped = quantum_convolution_grouped(q_image, groups)\n",
    "\n",
    "# Plot the results for MNIST image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(q_image, cmap='gray')\n",
    "axes[0].set_title('Original MNIST Image')\n",
    "axes[1].imshow(q_weighted, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the Lenna image\n",
    "q_weighted_lenna = quantum_convolution_weighted(q_lenna_image, kernels, weights)\n",
    "q_separable_lenna = quantum_convolution_separable(q_lenna_image, kx, ky)\n",
    "q_dilated_lenna = quantum_convolution_dilated(q_lenna_image, kernels, dilation_rate)\n",
    "q_grouped_lenna = quantum_convolution_grouped(q_lenna_image, groups)\n",
    "\n",
    "# Plot the results for Lenna image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(q_lenna_image, cmap='gray')\n",
    "axes[0].set_title('Original Lenna Image')\n",
    "axes[1].imshow(q_weighted_lenna, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_lenna, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_lenna, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_lenna, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the downloaded image\n",
    "q_weighted_download = quantum_convolution_weighted(q_download_image, kernels, weights)\n",
    "q_separable_download = quantum_convolution_separable(q_download_image, kx, ky)\n",
    "q_dilated_download = quantum_convolution_dilated(q_download_image, kernels, dilation_rate)\n",
    "q_grouped_download = quantum_convolution_grouped(q_download_image, groups)\n",
    "\n",
    "# Plot the results for downloaded image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(q_download_image, cmap='gray')\n",
    "axes[0].set_title('Original Downloaded Image')\n",
    "axes[1].imshow(q_weighted_download, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_download, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_download, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_download, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions for image loading and preprocessing\n",
    "def load_image(image_path, size=(28, 28)):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize(size)\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, titles, cmap='viridis'):\n",
    "    num_images = len(images)\n",
    "    cols = 3\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i], cmap=cmap)\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Turn off axes for any remaining empty subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Padding methods\n",
    "def cyclic_padding(image, pad_width):\n",
    "    return np.pad(image, pad_width=pad_width, mode='wrap')\n",
    "\n",
    "def symmetric_padding(image, pad_width):\n",
    "    return np.pad(image, pad_width=pad_width, mode='symmetric')\n",
    "\n",
    "# Quantum Convolution (QuC) with padding\n",
    "def quantum_convolution(image, kernel, padding, method='cyclic'):\n",
    "    if method == 'cyclic':\n",
    "        padded_image = cyclic_padding(image, padding)\n",
    "    elif method == 'symmetric':\n",
    "        padded_image = symmetric_padding(image, padding)\n",
    "    \n",
    "    # Convolution operation\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = (padded_image.shape[0] - kernel_size + 1, padded_image.shape[1] - kernel_size + 1)\n",
    "    output = np.zeros(output_size)\n",
    "    \n",
    "    for i in range(output_size[0]):\n",
    "        for j in range(output_size[1]):\n",
    "            output[i, j] = np.sum(padded_image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Stride and pooling operations\n",
    "def conv_with_stride(image, kernel, stride):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = ((image.shape[0] - kernel_size) // stride + 1, (image.shape[1] - kernel_size) // stride + 1)\n",
    "    output = np.zeros(output_size)\n",
    "    \n",
    "    for i in range(0, output_size[0] * stride, stride):\n",
    "        for j in range(0, output_size[1] * stride, stride):\n",
    "            if i + kernel_size <= image.shape[0] and j + kernel_size <= image.shape[1]:\n",
    "                output[i // stride, j // stride] = np.sum(image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def conv_with_padding_and_stride(image, kernel, padding, stride):\n",
    "    padded_image = cyclic_padding(image, padding)\n",
    "    return conv_with_stride(padded_image, kernel, stride)\n",
    "\n",
    "# Batch Normalization (BN) operation\n",
    "def batch_normalization(image, mean, variance, epsilon=1e-5):\n",
    "    return (image - mean) / np.sqrt(variance + epsilon)\n",
    "\n",
    "# Weighted kernels and grouped kernels\n",
    "def apply_weighted_kernels(image, kernels, weights):\n",
    "    result = np.zeros(image.shape)\n",
    "    for kernel, weight in zip(kernels, weights):\n",
    "        result += weight * quantum_convolution(image, kernel, padding=0)\n",
    "    return result\n",
    "\n",
    "def apply_grouped_kernels(image, grouped_kernels):\n",
    "    results = []\n",
    "    for group in grouped_kernels:\n",
    "        result = np.zeros(image.shape)\n",
    "        for kernel in group:\n",
    "            result += quantum_convolution(image, kernel, padding=0)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "# Amplitude Amplification (example placeholder)\n",
    "def amplitude_amplification(image):\n",
    "    return image  # Placeholder for actual amplitude amplification implementation\n",
    "\n",
    "# Entanglement (example placeholder)\n",
    "def entanglement_operation(image, kernel):\n",
    "    return quantum_convolution(image, kernel, padding=0)  # Placeholder for actual entanglement implementation\n",
    "\n",
    "# QFT and its inverse\n",
    "def quantum_fourier_transform(image):\n",
    "    # Placeholder for actual QFT implementation\n",
    "    return np.fft.fft2(image)\n",
    "\n",
    "def inverse_quantum_fourier_transform(image):\n",
    "    # Placeholder for actual inverse QFT implementation\n",
    "    return np.fft.ifft2(image)\n",
    "\n",
    "# Full QuC with padding and QFT integration\n",
    "def full_quantum_convolution(image, kernel, padding):\n",
    "    padded_image = cyclic_padding(image, padding)\n",
    "    padded_kernel = cyclic_padding(kernel, padding)\n",
    "    qft_image = quantum_fourier_transform(padded_image)\n",
    "    qft_kernel = quantum_fourier_transform(padded_kernel)\n",
    "    qft_result = qft_image * qft_kernel\n",
    "    result = inverse_quantum_fourier_transform(qft_result)\n",
    "    return np.real(result)\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = load_image(lenna_image_path)\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and process the Pepper image\n",
    "pepper_image_path = 'C:/Users/ACER/Desktop/pepper.jpg'\n",
    "pepper_image = load_image(pepper_image_path)\n",
    "q_pepper_image = pepper_image / 255.0\n",
    "\n",
    "# Example of using the defined functions\n",
    "sample_kernel = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])  # Example kernel\n",
    "padding = 5\n",
    "stride = 2\n",
    "\n",
    "# Processing with padding and stride\n",
    "padded_mnist_image = cyclic_padding(q_mnist_image, pad_width=padding)\n",
    "conv_result_mnist = quantum_convolution(q_mnist_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_mnist = conv_with_padding_and_stride(q_mnist_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "padded_lenna_image = cyclic_padding(q_lenna_image, pad_width=padding)\n",
    "conv_result_lenna = quantum_convolution(q_lenna_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_lenna = conv_with_padding_and_stride(q_lenna_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "padded_pepper_image = cyclic_padding(q_pepper_image, pad_width=padding)\n",
    "conv_result_pepper = quantum_convolution(q_pepper_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_pepper = conv_with_padding_and_stride(q_pepper_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "# Display results in a grid\n",
    "images = [\n",
    "    q_mnist_image, conv_result_mnist, conv_stride_result_mnist,\n",
    "    q_lenna_image, conv_result_lenna, conv_stride_result_lenna,\n",
    "    q_pepper_image, conv_result_pepper, conv_stride_result_pepper\n",
    "]\n",
    "titles = [\n",
    "    'MNIST Image', 'MNIST Convolution Result', 'MNIST Convolution with Padding and Stride Result',\n",
    "    'Lenna Image', 'Lenna Convolution Result', 'Lenna Convolution with Padding and Stride Result',\n",
    "    'Pepper Image', 'Pepper Convolution Result', 'Pepper Convolution with Padding and Stride Result'\n",
    "]\n",
    "\n",
    "plot_images(images, titles, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions for image loading and preprocessing\n",
    "def load_image(image_path, size=(28, 28)):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize(size)\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, titles, cmap='viridis'):\n",
    "    num_images = len(images)\n",
    "    cols = 3\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i], cmap=cmap)\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Turn off axes for any remaining empty subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Padding methods\n",
    "def cyclic_padding(image, pad_width):\n",
    "    return np.pad(image, pad_width=pad_width, mode='wrap')\n",
    "\n",
    "# Quantum Fourier Transform (QFT) and its inverse\n",
    "def quantum_fourier_transform(image):\n",
    "    return np.fft.fft2(image)\n",
    "\n",
    "def inverse_quantum_fourier_transform(image):\n",
    "    return np.fft.ifft2(image)\n",
    "\n",
    "# Quantum Convolution with Pre-padding and QFT\n",
    "def quantum_convolution_with_pre_padding(image, kernel, padding):\n",
    "    padded_image = cyclic_padding(image, pad_width=padding)\n",
    "    kernel_size = kernel.shape\n",
    "    padded_kernel = cyclic_padding(kernel, pad_width=((padded_image.shape[0] - kernel_size[0]) // 2, (padded_image.shape[1] - kernel_size[1]) // 2))\n",
    "    \n",
    "    # Ensure the padded kernel and image have the same size\n",
    "    padded_kernel = np.pad(kernel, pad_width=((0, padded_image.shape[0] - kernel_size[0]), (0, padded_image.shape[1] - kernel_size[1])), mode='constant', constant_values=0)\n",
    "    \n",
    "    qft_image = quantum_fourier_transform(padded_image)\n",
    "    qft_kernel = quantum_fourier_transform(padded_kernel)\n",
    "    \n",
    "    qft_result = qft_image * qft_kernel\n",
    "    result = inverse_quantum_fourier_transform(qft_result)\n",
    "    \n",
    "    return np.real(result)\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = load_image(lenna_image_path)\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and process the Pepper image\n",
    "pepper_image_path = 'C:/Users/ACER/Desktop/pepper.jpg'\n",
    "pepper_image = load_image(pepper_image_path)\n",
    "q_pepper_image = pepper_image / 255.0\n",
    "\n",
    "# Example of using the defined functions\n",
    "sample_kernel = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])  # Example kernel\n",
    "padding = 10\n",
    "\n",
    "# Quantum convolution with pre-padding\n",
    "conv_result_mnist = quantum_convolution_with_pre_padding(q_mnist_image, sample_kernel, padding=padding)\n",
    "conv_result_lenna = quantum_convolution_with_pre_padding(q_lenna_image, sample_kernel, padding=padding)\n",
    "conv_result_pepper = quantum_convolution_with_pre_padding(q_pepper_image, sample_kernel, padding=padding)\n",
    "\n",
    "# Display results in a grid\n",
    "images = [\n",
    "    q_mnist_image, conv_result_mnist,\n",
    "    q_lenna_image, conv_result_lenna,\n",
    "    q_pepper_image, conv_result_pepper\n",
    "]\n",
    "titles = [\n",
    "    'MNIST Image', 'MNIST Convolution Result',\n",
    "    'Lenna Image', 'Lenna Convolution Result',\n",
    "    'Pepper Image', 'Pepper Convolution Result'\n",
    "]\n",
    "\n",
    "plot_images(images, titles, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77841cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transform for the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "mnist_image = mnist_image.numpy()[0]\n",
    "\n",
    "# Load and process the Lena image\n",
    "lena_image = Image.open('C:/Users/ACER/Desktop/lena_256.jpg').convert('L')\n",
    "lena_image = lena_image.resize((28, 28))\n",
    "lena_image = np.array(lena_image) / 255.0\n",
    "\n",
    "# Load and process the Pepper image\n",
    "pepper_image = Image.open('C:/Users/ACER/Desktop/pepper.jpg').convert('L')\n",
    "pepper_image = pepper_image.resize((28, 28))\n",
    "pepper_image = np.array(pepper_image) / 255.0\n",
    "\n",
    "# Example kernel (You should define your own kernel)\n",
    "sample_kernel = np.ones((3, 3)) / 9  # Simple average kernel for demonstration\n",
    "padding = 25  # Example padding, adjust as needed\n",
    "\n",
    "def quantum_fourier_transform(image):\n",
    "    return np.fft.fft2(image)\n",
    "\n",
    "def inverse_quantum_fourier_transform(image):\n",
    "    return np.fft.ifft2(image)\n",
    "\n",
    "def quantum_convolution_with_pre_padding(image, kernel, padding):\n",
    "    # Calculate new padded sizes\n",
    "    padded_size = (image.shape[0] + 2 * padding, image.shape[1] + 2 * padding)\n",
    "    \n",
    "    # Apply padding to image and kernel\n",
    "    padded_image = np.pad(image, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    padded_kernel = np.pad(kernel, ((padding, padding), (padding, padding)), mode='constant')\n",
    "    \n",
    "    # Resize kernel to match the size of the padded image\n",
    "    padded_kernel = np.resize(padded_kernel, padded_image.shape)\n",
    "    \n",
    "    # Apply QFT\n",
    "    qft_image = quantum_fourier_transform(padded_image)\n",
    "    qft_kernel = quantum_fourier_transform(padded_kernel)\n",
    "    \n",
    "    # Convolution in frequency domain\n",
    "    qft_result = qft_image * qft_kernel\n",
    "    \n",
    "    # Inverse QFT\n",
    "    result = inverse_quantum_fourier_transform(qft_result)\n",
    "    \n",
    "    return np.abs(result)\n",
    "\n",
    "# Perform quantum convolution with pre-padding\n",
    "conv_result_mnist = quantum_convolution_with_pre_padding(mnist_image, sample_kernel, padding)\n",
    "conv_result_lena = quantum_convolution_with_pre_padding(lena_image, sample_kernel, padding)\n",
    "conv_result_pepper = quantum_convolution_with_pre_padding(pepper_image, sample_kernel, padding)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Original Images\n",
    "axs[0, 0].imshow(mnist_image, cmap='viridis')\n",
    "axs[0, 0].set_title('MNIST Image')\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].imshow(lena_image, cmap='viridis')\n",
    "axs[0, 1].set_title('Lena Image')\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "# Convolution Results\n",
    "axs[1, 0].imshow(conv_result_mnist, cmap='viridis')\n",
    "axs[1, 0].set_title('MNIST Convolution Result')\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].imshow(conv_result_lena, cmap='viridis')\n",
    "axs[1, 1].set_title('Lena Convolution Result')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b205d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transform for the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Load and process the Lena image\n",
    "def load_image(path, size=(28, 28)):\n",
    "    image = Image.open(path).convert('L')\n",
    "    image = image.resize(size)\n",
    "    return np.array(image) / 255.0\n",
    "\n",
    "lenna_image = load_image('C:/Users/ACER/Desktop/lena_256.jpg')\n",
    "download_image = load_image('C:/Users/ACER/Desktop/pepper.jpg')\n",
    "\n",
    "# Define a function to apply the weighted quantum convolution\n",
    "def quantum_convolution_weighted(q_i, q_k, weights):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for k, w in zip(q_k, weights):\n",
    "        result += w * (k * q_i)\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the separable quantum convolution\n",
    "def quantum_convolution_separable(q_i, q_kx, q_ky):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for kx, ky in zip(q_kx, q_ky):\n",
    "        result += np.outer(kx, ky) * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the dilated quantum convolution\n",
    "def quantum_convolution_dilated(q_i, q_k, d):\n",
    "    result = np.zeros_like(q_i)\n",
    "    kernel_size = q_k[0].shape  # Assuming all kernels have the same size\n",
    "\n",
    "    for k in q_k:\n",
    "        dilated_k = np.zeros_like(q_i)\n",
    "        for i in range(0, q_i.shape[0] - kernel_size[0] + 1, d):\n",
    "            for j in range(0, q_i.shape[1] - kernel_size[1] + 1, d):\n",
    "                dilated_k[i:i+kernel_size[0], j:j+kernel_size[1]] = k\n",
    "        result += dilated_k * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the grouped quantum convolution\n",
    "def quantum_convolution_grouped(q_i, q_kgroups):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for group in q_kgroups:\n",
    "        group_result = np.zeros_like(q_i)\n",
    "        for k in group:\n",
    "            group_result += k * q_i\n",
    "        result += group_result\n",
    "    return result\n",
    "\n",
    "# Example kernels and weights\n",
    "kernels = [np.random.rand(28, 28) for _ in range(3)]\n",
    "weights = [0.3, 0.5, 0.2]\n",
    "kx = [np.random.rand(28) for _ in range(3)]\n",
    "ky = [np.random.rand(28) for _ in range(3)]\n",
    "groups = [[np.random.rand(28, 28) for _ in range(2)], [np.random.rand(28, 28) for _ in range(2)]]\n",
    "dilation_rate = 2\n",
    "\n",
    "# Apply the quantum convolution operations to the MNIST image\n",
    "q_weighted = quantum_convolution_weighted(q_image, kernels, weights)\n",
    "q_separable = quantum_convolution_separable(q_image, kx, ky)\n",
    "q_dilated = quantum_convolution_dilated(q_image, kernels, dilation_rate)\n",
    "q_grouped = quantum_convolution_grouped(q_image, groups)\n",
    "\n",
    "# Plot the results for MNIST image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(q_image, cmap='gray')\n",
    "axes[0].set_title('Original MNIST Image')\n",
    "axes[1].imshow(q_weighted, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the Lena image\n",
    "q_weighted_lenna = quantum_convolution_weighted(lenna_image, kernels, weights)\n",
    "q_separable_lenna = quantum_convolution_separable(lenna_image, kx, ky)\n",
    "q_dilated_lenna = quantum_convolution_dilated(lenna_image, kernels, dilation_rate)\n",
    "q_grouped_lenna = quantum_convolution_grouped(lenna_image, groups)\n",
    "\n",
    "# Plot the results for Lenna image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(lenna_image, cmap='gray')\n",
    "axes[0].set_title('Original Lenna Image')\n",
    "axes[1].imshow(q_weighted_lenna, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_lenna, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_lenna, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_lenna, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the downloaded image\n",
    "q_weighted_download = quantum_convolution_weighted(download_image, kernels, weights)\n",
    "q_separable_download = quantum_convolution_separable(download_image, kx, ky)\n",
    "q_dilated_download = quantum_convolution_dilated(download_image, kernels, dilation_rate)\n",
    "q_grouped_download = quantum_convolution_grouped(download_image, groups)\n",
    "\n",
    "# Plot the results for downloaded image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(download_image, cmap='gray')\n",
    "axes[0].set_title('Original Downloaded Image')\n",
    "axes[1].imshow(q_weighted_download, cmap='gray')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_download, cmap='gray')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_download, cmap='gray')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_download, cmap='gray')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transform for the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "image, _ = trainset[0]\n",
    "q_image = np.abs(image.numpy()[0])\n",
    "\n",
    "# Load and process the Lena image\n",
    "def load_image(path, size=(28, 28)):\n",
    "    image = Image.open(path).convert('L')\n",
    "    image = image.resize(size)\n",
    "    return np.array(image) / 255.0\n",
    "\n",
    "lenna_image = load_image('C:/Users/ACER/Desktop/lena_256.jpg')\n",
    "download_image = load_image('C:/Users/ACER/Desktop/pepper.jpg')\n",
    "\n",
    "# Define a function to apply the weighted quantum convolution\n",
    "def quantum_convolution_weighted(q_i, q_k, weights):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for k, w in zip(q_k, weights):\n",
    "        result += w * (k * q_i)\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the separable quantum convolution\n",
    "def quantum_convolution_separable(q_i, q_kx, q_ky):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for kx, ky in zip(q_kx, q_ky):\n",
    "        result += np.outer(kx, ky) * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the dilated quantum convolution\n",
    "def quantum_convolution_dilated(q_i, q_k, d):\n",
    "    result = np.zeros_like(q_i)\n",
    "    kernel_size = q_k[0].shape  # Assuming all kernels have the same size\n",
    "\n",
    "    for k in q_k:\n",
    "        dilated_k = np.zeros_like(q_i)\n",
    "        for i in range(0, q_i.shape[0] - kernel_size[0] + 1, d):\n",
    "            for j in range(0, q_i.shape[1] - kernel_size[1] + 1, d):\n",
    "                dilated_k[i:i+kernel_size[0], j:j+kernel_size[1]] = k\n",
    "        result += dilated_k * q_i\n",
    "    return result\n",
    "\n",
    "# Define a function to apply the grouped quantum convolution\n",
    "def quantum_convolution_grouped(q_i, q_kgroups):\n",
    "    result = np.zeros_like(q_i)\n",
    "    for group in q_kgroups:\n",
    "        group_result = np.zeros_like(q_i)\n",
    "        for k in group:\n",
    "            group_result += k * q_i\n",
    "        result += group_result\n",
    "    return result\n",
    "\n",
    "# Example kernels and weights\n",
    "kernels = [np.random.rand(28, 28) for _ in range(3)]\n",
    "weights = [0.3, 0.5, 0.2]\n",
    "kx = [np.random.rand(28) for _ in range(3)]\n",
    "ky = [np.random.rand(28) for _ in range(3)]\n",
    "groups = [[np.random.rand(28, 28) for _ in range(2)], [np.random.rand(28, 28) for _ in range(2)]]\n",
    "dilation_rate = 2\n",
    "\n",
    "# Apply the quantum convolution operations to the MNIST image\n",
    "q_weighted = quantum_convolution_weighted(q_image, kernels, weights)\n",
    "q_separable = quantum_convolution_separable(q_image, kx, ky)\n",
    "q_dilated = quantum_convolution_dilated(q_image, kernels, dilation_rate)\n",
    "q_grouped = quantum_convolution_grouped(q_image, groups)\n",
    "\n",
    "# Plot the results for MNIST image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(q_image, cmap='viridis')\n",
    "axes[0].set_title('Original MNIST Image')\n",
    "axes[1].imshow(q_weighted, cmap='viridis')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable, cmap='viridis')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated, cmap='viridis')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped, cmap='viridis')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the Lena image\n",
    "q_weighted_lenna = quantum_convolution_weighted(lenna_image, kernels, weights)\n",
    "q_separable_lenna = quantum_convolution_separable(lenna_image, kx, ky)\n",
    "q_dilated_lenna = quantum_convolution_dilated(lenna_image, kernels, dilation_rate)\n",
    "q_grouped_lenna = quantum_convolution_grouped(lenna_image, groups)\n",
    "\n",
    "# Plot the results for Lenna image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(lenna_image, cmap='viridis')\n",
    "axes[0].set_title('Original Lenna Image')\n",
    "axes[1].imshow(q_weighted_lenna, cmap='viridis')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_lenna, cmap='viridis')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_lenna, cmap='viridis')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_lenna, cmap='viridis')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n",
    "\n",
    "# Apply the quantum convolution operations to the downloaded image\n",
    "q_weighted_download = quantum_convolution_weighted(download_image, kernels, weights)\n",
    "q_separable_download = quantum_convolution_separable(download_image, kx, ky)\n",
    "q_dilated_download = quantum_convolution_dilated(download_image, kernels, dilation_rate)\n",
    "q_grouped_download = quantum_convolution_grouped(download_image, groups)\n",
    "\n",
    "# Plot the results for downloaded image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(download_image, cmap='viridis')\n",
    "axes[0].set_title('Original Downloaded Image')\n",
    "axes[1].imshow(q_weighted_download, cmap='viridis')\n",
    "axes[1].set_title('Weighted Quantum Convolution')\n",
    "axes[2].imshow(q_separable_download, cmap='viridis')\n",
    "axes[2].set_title('Separable Quantum Convolution')\n",
    "axes[3].imshow(q_dilated_download, cmap='viridis')\n",
    "axes[3].set_title('Dilated Quantum Convolution')\n",
    "axes[4].imshow(q_grouped_download, cmap='viridis')\n",
    "axes[4].set_title('Grouped Quantum Convolution')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
