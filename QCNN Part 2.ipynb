{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b44844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Helper functions for image loading and preprocessing\n",
    "def load_image(image_path, size=(28, 28)):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize(size)\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, titles, cmap='viridis'):\n",
    "    num_images = len(images)\n",
    "    cols = 3\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i], cmap=cmap)\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Turn off axes for any remaining empty subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Padding methods\n",
    "def cyclic_padding(image, pad_width):\n",
    "    return np.pad(image, pad_width=pad_width, mode='wrap')\n",
    "\n",
    "def symmetric_padding(image, pad_width):\n",
    "    return np.pad(image, pad_width=pad_width, mode='symmetric')\n",
    "\n",
    "# Quantum Convolution (QuC) with padding\n",
    "def quantum_convolution(image, kernel, padding, method='cyclic'):\n",
    "    if method == 'cyclic':\n",
    "        padded_image = cyclic_padding(image, padding)\n",
    "    elif method == 'symmetric':\n",
    "        padded_image = symmetric_padding(image, padding)\n",
    "    \n",
    "    # Convolution operation\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = (padded_image.shape[0] - kernel_size + 1, padded_image.shape[1] - kernel_size + 1)\n",
    "    output = np.zeros(output_size)\n",
    "    \n",
    "    for i in range(output_size[0]):\n",
    "        for j in range(output_size[1]):\n",
    "            output[i, j] = np.sum(padded_image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Stride and pooling operations\n",
    "def conv_with_stride(image, kernel, stride):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = ((image.shape[0] - kernel_size) // stride + 1, (image.shape[1] - kernel_size) // stride + 1)\n",
    "    output = np.zeros(output_size)\n",
    "    \n",
    "    for i in range(0, output_size[0] * stride, stride):\n",
    "        for j in range(0, output_size[1] * stride, stride):\n",
    "            if i + kernel_size <= image.shape[0] and j + kernel_size <= image.shape[1]:\n",
    "                output[i // stride, j // stride] = np.sum(image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def conv_with_padding_and_stride(image, kernel, padding, stride):\n",
    "    padded_image = cyclic_padding(image, padding)\n",
    "    return conv_with_stride(padded_image, kernel, stride)\n",
    "\n",
    "# Batch Normalization (BN) operation\n",
    "def batch_normalization(image, mean, variance, epsilon=1e-5):\n",
    "    return (image - mean) / np.sqrt(variance + epsilon)\n",
    "\n",
    "# Weighted kernels and grouped kernels\n",
    "def apply_weighted_kernels(image, kernels, weights):\n",
    "    result = np.zeros(image.shape)\n",
    "    for kernel, weight in zip(kernels, weights):\n",
    "        result += weight * quantum_convolution(image, kernel, padding=0)\n",
    "    return result\n",
    "\n",
    "def apply_grouped_kernels(image, grouped_kernels):\n",
    "    results = []\n",
    "    for group in grouped_kernels:\n",
    "        result = np.zeros(image.shape)\n",
    "        for kernel in group:\n",
    "            result += quantum_convolution(image, kernel, padding=0)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "# Amplitude Amplification (example placeholder)\n",
    "def amplitude_amplification(image):\n",
    "    return image  # Placeholder for actual amplitude amplification implementation\n",
    "\n",
    "# Entanglement (example placeholder)\n",
    "def entanglement_operation(image, kernel):\n",
    "    return quantum_convolution(image, kernel, padding=0)  # Placeholder for actual entanglement implementation\n",
    "\n",
    "# QFT and its inverse\n",
    "def quantum_fourier_transform(image):\n",
    "    # Placeholder for actual QFT implementation\n",
    "    return np.fft.fft2(image)\n",
    "\n",
    "def inverse_quantum_fourier_transform(image):\n",
    "    # Placeholder for actual inverse QFT implementation\n",
    "    return np.fft.ifft2(image)\n",
    "\n",
    "# Full QuC with padding and QFT integration\n",
    "def full_quantum_convolution(image, kernel, padding):\n",
    "    padded_image = cyclic_padding(image, padding)\n",
    "    padded_kernel = cyclic_padding(kernel, padding)\n",
    "    qft_image = quantum_fourier_transform(padded_image)\n",
    "    qft_kernel = quantum_fourier_transform(padded_kernel)\n",
    "    qft_result = qft_image * qft_kernel\n",
    "    result = inverse_quantum_fourier_transform(qft_result)\n",
    "    return np.real(result)\n",
    "\n",
    "# Load MNIST dataset and preprocess\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "mnist_image, _ = trainset[0]\n",
    "q_mnist_image = np.abs(mnist_image.numpy()[0])\n",
    "\n",
    "# Load and process the Lenna image\n",
    "lenna_image_path = 'C:/Users/ACER/Desktop/lena_256.jpg'\n",
    "lenna_image = cv2.imread(lenna_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if lenna_image is None:\n",
    "    raise ValueError(f\"Error loading Lenna image from path: {lenna_image_path}\")\n",
    "lenna_image = cv2.resize(lenna_image, (28, 28))\n",
    "q_lenna_image = lenna_image / 255.0\n",
    "\n",
    "# Load and process the Pepper image\n",
    "pepper_image_path = 'C:/Users/ACER/Desktop/download.jpg'\n",
    "pepper_image = cv2.imread(pepper_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if pepper_image is None:\n",
    "    raise ValueError(f\"Error loading Pepper image from path: {pepper_image_path}\")\n",
    "pepper_image = cv2.resize(pepper_image, (28, 28))\n",
    "q_pepper_image = pepper_image / 255.0\n",
    "\n",
    "# Example of using the defined functions\n",
    "sample_kernel = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])  # Example kernel\n",
    "padding = 5\n",
    "stride = 2\n",
    "\n",
    "# Processing with padding and stride\n",
    "padded_mnist_image = cyclic_padding(q_mnist_image, pad_width=padding)\n",
    "conv_result_mnist = quantum_convolution(q_mnist_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_mnist = conv_with_padding_and_stride(q_mnist_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "padded_lenna_image = cyclic_padding(q_lenna_image, pad_width=padding)\n",
    "conv_result_lenna = quantum_convolution(q_lenna_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_lenna = conv_with_padding_and_stride(q_lenna_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "padded_pepper_image = cyclic_padding(q_pepper_image, pad_width=padding)\n",
    "conv_result_pepper = quantum_convolution(q_pepper_image, sample_kernel, padding=padding)\n",
    "conv_stride_result_pepper = conv_with_padding_and_stride(q_pepper_image, sample_kernel, padding=padding, stride=stride)\n",
    "\n",
    "# Display results in a grid\n",
    "images = [\n",
    "    q_mnist_image, conv_result_mnist, conv_stride_result_mnist,\n",
    "    q_lenna_image, conv_result_lenna, conv_stride_result_lenna,\n",
    "    q_pepper_image, conv_result_pepper, conv_stride_result_pepper\n",
    "]\n",
    "titles = [\n",
    "    'MNIST Oroginal Image', 'MNIST Convolution Result', 'MNIST Convolution with Padding and Stride Result',\n",
    "    'Lenna Oroginal Image', 'Lenna Convolution Result', 'Lenna Convolution with Padding and Stride Result',\n",
    "    'Pepper Oroginal Image', 'Pepper Convolution Result', 'Pepper Convolution with Padding and Stride Result'\n",
    "]\n",
    "\n",
    "plot_images(images, titles, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca302b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
